{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create directory for dataset\n",
    "os.makedirs('dataset', exist_ok=True)\n",
    "\n",
    "# Updated dataset link - using a more reliable GitHub repository\n",
    "print(\"Using GitHub repository for Sen1Floods11 dataset...\")\n",
    "url = 'https://github.com/cloudtostreet/Sen1Floods11/archive/refs/heads/master.zip'\n",
    "output = 'dataset/sen1floods11.zip'\n",
    "\n",
    "# Check if the dataset is already downloaded\n",
    "if not os.path.exists(output):\n",
    "    print(\"Downloading dataset...\")\n",
    "    !wget {url} -O {output}\n",
    "    \n",
    "    # Extract the dataset\n",
    "    print(\"Extracting dataset...\")\n",
    "    with zipfile.ZipFile(output, 'r') as zip_ref:\n",
    "        zip_ref.extractall('dataset')\n",
    "else:\n",
    "    print(\"Dataset already downloaded.\")\n",
    "\n",
    "# Find the SAR and mask files in the dataset\n",
    "# Note: The paths might need adjustment based on the actual dataset structure\n",
    "flood_sar_paths = sorted(glob('dataset/Sen1Floods11-master/data/flood_events/bolivia/S1/**/*VH*.tif', recursive=True))\n",
    "non_flood_sar_paths = sorted(glob('dataset/Sen1Floods11-master/data/flood_events/bolivia/S1_non_flood/**/*VH*.tif', recursive=True))\n",
    "flood_mask_paths = sorted(glob('dataset/Sen1Floods11-master/data/flood_events/bolivia/flood_mask/*.tif'))\n",
    "\n",
    "# Print counts to verify\n",
    "print(f\"Found {len(flood_sar_paths)} flood SAR images\")\n",
    "print(f\"Found {len(non_flood_sar_paths)} non-flood SAR images\")\n",
    "print(f\"Found {len(flood_mask_paths)} flood mask images\")\n",
    "\n",
    "# Ensure we have matching sets\n",
    "min_count = min(len(flood_sar_paths), len(non_flood_sar_paths), len(flood_mask_paths))\n",
    "flood_sar_paths = flood_sar_paths[:min_count]\n",
    "non_flood_sar_paths = non_flood_sar_paths[:min_count]\n",
    "flood_mask_paths = flood_mask_paths[:min_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Alternative dataset using Hugging Face dataset\n",
    "print(\"Using alternative Sen1Floods11 dataset...\")\n",
    "\n",
    "# Install huggingface datasets if needed\n",
    "!pip install datasets -q\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load dataset from Hugging Face\n",
    "dataset = load_dataset(\"intelligent-factory/sen1floods11\", split=\"train\")\n",
    "print(f\"Dataset loaded with {len(dataset)} samples\")\n",
    "\n",
    "# Create directories\n",
    "os.makedirs('dataset/sen1floods11/flood_sar', exist_ok=True)\n",
    "os.makedirs('dataset/sen1floods11/non_flood_sar', exist_ok=True)\n",
    "os.makedirs('dataset/sen1floods11/flood_mask', exist_ok=True)\n",
    "\n",
    "# Save a sample of images to disk\n",
    "for i, sample in enumerate(dataset.select(range(min(100, len(dataset))))):\n",
    "    # Save flood SAR\n",
    "    flood_path = f'dataset/sen1floods11/flood_sar/image_{i}.tif'\n",
    "    with rasterio.open(flood_path, 'w', \n",
    "                      driver='GTiff', \n",
    "                      height=sample['flood_sar'].shape[0], \n",
    "                      width=sample['flood_sar'].shape[1], \n",
    "                      count=1, \n",
    "                      dtype=sample['flood_sar'].dtype) as dst:\n",
    "        dst.write(sample['flood_sar'], 1)\n",
    "    \n",
    "    # Save non-flood SAR\n",
    "    non_flood_path = f'dataset/sen1floods11/non_flood_sar/image_{i}.tif'\n",
    "    with rasterio.open(non_flood_path, 'w', \n",
    "                      driver='GTiff', \n",
    "                      height=sample['non_flood_sar'].shape[0], \n",
    "                      width=sample['non_flood_sar'].shape[1], \n",
    "                      count=1, \n",
    "                      dtype=sample['non_flood_sar'].dtype) as dst:\n",
    "        dst.write(sample['non_flood_sar'], 1)\n",
    "    \n",
    "    # Save flood mask\n",
    "    mask_path = f'dataset/sen1floods11/flood_mask/image_{i}.tif'\n",
    "    with rasterio.open(mask_path, 'w', \n",
    "                      driver='GTiff', \n",
    "                      height=sample['flood_mask'].shape[0], \n",
    "                      width=sample['flood_mask'].shape[1], \n",
    "                      count=1, \n",
    "                      dtype=sample['flood_mask'].dtype) as dst:\n",
    "        dst.write(sample['flood_mask'], 1)\n",
    "\n",
    "# Get new paths\n",
    "flood_sar_paths = sorted(glob('dataset/sen1floods11/flood_sar/*.tif'))\n",
    "non_flood_sar_paths = sorted(glob('dataset/sen1floods11/non_flood_sar/*.tif'))\n",
    "flood_mask_paths = sorted(glob('dataset/sen1floods11/flood_mask/*.tif'))\n",
    "\n",
    "print(f\"Found {len(flood_sar_paths)} flood SAR images\")\n",
    "print(f\"Found {len(non_flood_sar_paths)} non-flood SAR images\")\n",
    "print(f\"Found {len(flood_mask_paths)} flood mask images\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
