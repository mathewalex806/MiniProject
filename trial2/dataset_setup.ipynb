{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sen1Floods11 Dataset Setup\n",
    "\n",
    "This notebook handles downloading and processing the Sen1Floods11 dataset from the official GitHub repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import zipfile\n",
    "import wget\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging and constants\n",
    "def setup_logging():\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s'\n",
    "    )\n",
    "\n",
    "DATASET_URL = \"https://github.com/cloudtostreet/Sen1Floods11/archive/refs/heads/master.zip\"\n",
    "DATASET_PATH = \"dataset/sen1floods11.zip\"\n",
    "DATA_DIR = Path('dataset/Sen1Floods11-master/data')\n",
    "\n",
    "setup_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dataset(url, save_path):\n",
    "    logging.info(f\"Downloading dataset from {url}\")\n",
    "    if not os.path.exists('dataset'):\n",
    "        os.makedirs('dataset')\n",
    "    if not os.path.exists(save_path):\n",
    "        wget.download(url, save_path)\n",
    "        print(\"\\nDownload complete!\")\n",
    "    else:\n",
    "        logging.info(\"Dataset zip already exists\")\n",
    "\n",
    "def extract_dataset(zip_path, extract_path):\n",
    "    if not os.path.exists(DATA_DIR):\n",
    "        logging.info(\"Extracting dataset...\")\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_path)\n",
    "        logging.info(\"Extraction complete!\")\n",
    "    else:\n",
    "        logging.info(\"Dataset already extracted\")\n",
    "\n",
    "def find_images():\n",
    "    flood_sar = list(DATA_DIR.rglob(\"*flood*/S1*.tif\"))\n",
    "    nonflood_sar = list(DATA_DIR.rglob(\"*non_flood*/S1*.tif\"))\n",
    "    flood_masks = list(DATA_DIR.rglob(\"*flood*/flood_mask*.tif\"))\n",
    "    \n",
    "    logging.info(f\"Found {len(flood_sar)} flood SAR images\")\n",
    "    logging.info(f\"Found {len(nonflood_sar)} non-flood SAR images\")\n",
    "    logging.info(f\"Found {len(flood_masks)} flood mask images\")\n",
    "    \n",
    "    return flood_sar, nonflood_sar, flood_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sample(sar_path, mask_path=None):\n",
    "    with rasterio.open(sar_path) as src:\n",
    "        sar_img = src.read(1)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.title('SAR Image')\n",
    "    plt.imshow(sar_img, cmap='gray')\n",
    "    \n",
    "    if mask_path:\n",
    "        with rasterio.open(mask_path) as src:\n",
    "            mask = src.read(1)\n",
    "        plt.subplot(122)\n",
    "        plt.title('Flood Mask')\n",
    "        plt.imshow(mask, cmap='binary')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and process dataset\n",
    "try:\n",
    "    download_dataset(DATASET_URL, DATASET_PATH)\n",
    "    extract_dataset(DATASET_PATH, 'dataset')\n",
    "    flood_sar, nonflood_sar, flood_masks = find_images()\n",
    "    \n",
    "    # Visualize first flood sample if available\n",
    "    if flood_sar and flood_masks:\n",
    "        visualize_sample(str(flood_sar[0]), str(flood_masks[0]))\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error processing dataset: {str(e)}\")\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
